---
description: 
globs: 
alwaysApply: false
---
# Cursor Rules for Technical Assessment System

## Data Handling

1. Always normalize skill IDs when performing lookups:
   ```python
   normalized_id = normalize_skill_id(skill_id)
   ```

2. Use defensive unpacking for nested JSON structures:
   ```python
   # Avoid this:
   score = data['result']['skills'][0]['score']
   
   # Do this instead:
   score = data.get('result', {}).get('skills', [{}])[0].get('score', 0)
   ```

3. Validate all external data before processing:
   ```python
   if not isinstance(skills_data, list):
       skills_data = [skills_data] if isinstance(skills_data, dict) else []
   ```

## Database Operations

1. Check for column existence before trying to update:
   ```python
   try:
       supabase.table('table_name').select('column_name').limit(1).execute()
       # Column exists, proceed with update
   except Exception:
       # Use alternative storage method
   ```

2. Implement fallback storage mechanisms for new features:
   ```python
   # Try primary storage method
   # If fails, try session_data or separate table
   ```

3. Use transactions for multi-step database operations:
   ```python
   # Not just sequential operations that could leave DB in inconsistent state
   ```

## Error Handling

1. Always catch and log specific exceptions:
   ```python
   try:
       # operation
   except KeyError as e:
       logger.error(f"Missing key: {str(e)}")
   except ValueError as e:
       logger.error(f"Invalid value: {str(e)}")
   except Exception as e:
       logger.error(f"Unexpected error: {str(e)}")
       logger.error(traceback.format_exc())
   ```

2. Return meaningful error messages to clients:
   ```python
   return Response({
       'error': 'Failed to process data',
       'details': str(e),
       'code': 'DATA_PROCESSING_ERROR'
   }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
   ```

3. Implement exponential backoff for API calls:
   ```python
   # Especially for LLM and external service calls
   ```

## Logging Standards

1. Use structured logging:
   ```python
   logger.info(f"Processing question", extra={
       'question_id': question_id,
       'user_id': user_id,
       'timestamp': datetime.utcnow().isoformat()
   })
   ```

2. Include correlation IDs in logs:
   ```python
   logger.info(f"Starting gap analysis", extra={'correlation_id': baseline_id})
   ```

3. Log skill competency results with consistent formatting:
   ```python
   logger.info(f"{color_code}{skill_name} (ID: {skill_id}): {competency}/100 - {level}\033[0m")
   ```

## Performance Optimization

1. Use bulk operations when possible:
   ```python
   # Instead of multiple single updates, use:
   supabase.table('table_name').upsert(multiple_records).execute()
   ```

2. Implement caching for repeated skill lookups:
   ```python
   normalized_skill_map = {}  # Create once, reuse for all lookups
   ```

3. Minimize LLM token usage:
   ```python
   # Provide clear, concise prompts
   # Only include necessary context
   # Use most efficient model for each task
   ```

## Code Structure

1. Modularize competency evaluation logic:
   ```python
   # Extract complex evaluation into separate functions
   def evaluate_specific_skill(skill_type, question, answer):
       # Specialized logic
   ```

2. Use type hints consistently:
   ```python
   def normalize_skill_id(skill_id: str) -> str:
       # Function body
   ```

3. Implement proper dependency injection:
   ```python
   def analyze_questions(questions: List[Dict], supabase_client: Client):
       # Function using injected client
   ```

## Testing

1. Write tests for skill ID normalization:
   ```python
   def test_normalize_skill_id():
       assert normalize_skill_id("Skill_HTML5") == "html5"
   ```

2. Mock external services in tests:
   ```python
   @patch('openai.ChatCompletion.create')
   def test_evaluate_competency(mock_openai):
       mock_openai.return_value = {'choices': [{'message': {'content': '{"score": 75}'}}]}
       # Test logic
   ```

3. Test edge cases for JSON parsing:
   ```python
   # Test with empty data, malformed data, etc.
   ```

## Documentation

1. Include expected JSON formats in docstrings:
   ```python
   def process_skill_matrix(skill_matrix):
       """
       Process a skill matrix.
       
       Expected format:
       {
           "category": {
               "skills": [
                   {"id": "skill1", "name": "Skill 1", "competency": 75}
               ]
           }
       }
       """
   ```

2. Document all database schemas:
   ```python
   # Add schema documentation to README.md or dedicated SCHEMA.md
   ```

3. Keep sample input/output examples up-to-date:
   ```python
   # Update examples when data structures change
   ```

## Changelog Management

1. When instructed to "update changelog", modify the CHANGELOG.md file:
   ```markdown
   # Follow the Keep a Changelog format (https://keepachangelog.com)
   # Group changes under Added, Changed, Fixed, Removed, etc.
   ```

2. Always use the date specified by the user:
   ```markdown
   ## [1.1.1] - 2023-10-25  # Use the exact date mentioned by user
   
   ### Added
   - New feature 1
   - New feature 2
   
   ### Fixed
   - Bug fix 1
   - Bug fix 2
   
   ### Changed
   - Improvement 1
   - Improvement 2
   ```

3. Follow semantic versioning for version numbers:
   ```
   MAJOR.MINOR.PATCH
   - MAJOR: Breaking changes
   - MINOR: New features, backward compatible
   - PATCH: Bug fixes, backward compatible
   ```

4. Add changelog entries at the top of the file under the most recent version:
   ```markdown
   # Changelog
   
   ## [NEW_VERSION] - DATE
   
   ### Category
   - New entries
   
   ## [PREVIOUS_VERSION] - PREVIOUS_DATE
   ```

5. When making significant changes, ensure the changelog is updated in the same commit.
